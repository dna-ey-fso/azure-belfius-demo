# Nutter pipeline for SparkSQL Tests

trigger:
  branches:
    include:
    - single-tech/*

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '3.5'

# Thie pipeline for Databricks should be replaced by the ADF ones here
# https://github.com/dna-ey-fso/azure-mdw-adf-demo/tree/main/e2e_samples/parking_sensors/devops
# We can implement the CI part as Azure pipelines and keep the CD for release pipelines
# This pipeline will create an artifact in Azure Artifacts (CI)
# The output artifact will be consumed by an Azure Release Pipeline (CD)

# - task: configuredatabricks@0
#   displayName: 'Configure Databricks CLI'
#   inputs:
#     url: $(databricks_host)
#     token: $(databricks_token)

# - task: deploynotebooks@0
#   displayName: 'Publish notebooks to test workspace'
#   inputs:
#     notebooksFolderPath: $(notebook_folder_path)
#     workspaceFolder: $(workspace_folder)

# - script: |
#     pip install nutter
#   displayName: 'Install Nutter'

# - script: |
#     nutter run $SEARCHFOLDER $CLUSTER --recursive --junit_report
#   displayName: 'Execute Nutter'
#   env:
#       SEARCHFOLDER: $(test_search_folder)
#       CLUSTER: $(clusterID)
#       DATABRICKS_HOST: $(databricks_host)
#       DATABRICKS_TOKEN: $(databricks_token)

# - task: PublishTestResults@2
#   inputs:
#     testResultsFormat: 'JUnit'
#     testResultsFiles: '**/test-*.xml'
#     testRunTitle: 'Publish Nutter results'
#   condition: succeededOrFailed()